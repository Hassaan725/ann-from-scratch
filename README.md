# ann-from-scratch
A simple implementation of an Artificial Neural Network (ANN) from scratch using Python and NumPy, including forward and backward propagation.
# Artificial Neural Network (ANN) from Scratch 🧠

This project provides a simple yet complete implementation of a basic **Artificial Neural Network (ANN)** using **Python** and **NumPy**, without relying on high-level libraries like TensorFlow or PyTorch.

The goal is to demonstrate how neural networks function **internally**, focusing on the core concepts of forward propagation, backpropagation, and weight updates using gradient descent.

---

## 📌 Features

- ✅ Manual **Forward Propagation**
- ✅ **Sigmoid Activation Function**
- ✅ Loss calculation using **Mean Squared Error (MSE)**
- ✅ Manual **Backpropagation**
- ✅ Weight updates using **Gradient Descent**
- ✅ Simple input-output training loop

---

## 🧠 Concepts Covered

- Neurons and layers
- Activation functions
- Feedforward computation
- Error calculation
- Gradient calculation
- Backpropagation (chain rule)
- Updating weights

---

## 🧪 Sample Architecture

- Input Layer: 3 features
- Hidden Layer: 4 neurons (with sigmoid)
- Output Layer: 1 neuron (with sigmoid)

---

## 🖥️ Technologies Used

- Python
- NumPy
- Jupyter Notebook (for demonstration)

---

## 🚀 Getting Started

### 1. Clone the repository
```bash
git clone https://github.com/your-username/ann-from-scratch.git
cd ann-from-scratch

